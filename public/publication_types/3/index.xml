<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>3 | Bingbing Wen</title>
    <link>http://localhost:1313/publication_types/3/</link>
      <atom:link href="http://localhost:1313/publication_types/3/index.xml" rel="self" type="application/rss+xml" />
    <description>3</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 20 Jan 2026 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu_fb558a5ed99f547e.png</url>
      <title>3</title>
      <link>http://localhost:1313/publication_types/3/</link>
    </image>
    
    <item>
      <title>Clarify or Answer: Reinforcement Learning for Agentic VQA with Context Under-specification</title>
      <link>http://localhost:1313/publications/clarify-or-answer-agentic-vqa/</link>
      <pubDate>Tue, 20 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/clarify-or-answer-agentic-vqa/</guid>
      <description>&lt;p&gt;We introduce a reinforcement learning framework for agentic VQA that explicitly models whether an agent should ask for clarification or answer directly when faced with underspecified visual and textual context.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorized Clustered LoRA Merging for Multi-Task Interference</title>
      <link>http://localhost:1313/publications/tensorized-clustered-lora-merging/</link>
      <pubDate>Fri, 15 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/tensorized-clustered-lora-merging/</guid>
      <description>&lt;p&gt;We introduce tensorized clustered LoRA merging to address multi-task interference when large language models are adapted to many tasks via low-rank adapters, improving performance and parameter efficiency.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MMMG: A Comprehensive and Reliable Evaluation Suite for Multitask Multimodal Generation</title>
      <link>http://localhost:1313/publications/mmmg-multitask-multimodal-generation/</link>
      <pubDate>Tue, 20 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/mmmg-multitask-multimodal-generation/</guid>
      <description>&lt;p&gt;MMMG is an evaluation suite for multitask multimodal generation, enabling more reliable assessment of large multimodal models across a wide range of generation tasks and modalities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>InfoVisDial: An Informative Visual Dialogue Dataset by Bridging Large Multimodal and Language Models</title>
      <link>http://localhost:1313/publications/infovisdial/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/infovisdial/</guid>
      <description>&lt;p&gt;We present InfoVisDial, a comprehensive visual dialogue dataset created by bridging large multimodal and language models to enable informative conversations about visual content. This work was conducted during an internship at Microsoft Azure AI.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>EGCR: Explanation Generation for Conversational Recommendation</title>
      <link>http://localhost:1313/publications/egcr-conversational-recommendation-explanations/</link>
      <pubDate>Sat, 20 Aug 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/egcr-conversational-recommendation-explanations/</guid>
      <description>&lt;p&gt;We propose EGCR, a framework for generating explanations in conversational recommendation scenarios that supports multi-turn dialogue and user-centric justification of recommendations.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards Generating Robust, Fair, and Emotion-Aware Explanations for Recommender Systems</title>
      <link>http://localhost:1313/publications/robust-fair-emotion-aware-explanations/</link>
      <pubDate>Sat, 20 Aug 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/robust-fair-emotion-aware-explanations/</guid>
      <description>&lt;p&gt;We explore methods for generating explanations in recommender systems that remain robust under perturbations, treat users fairly, and take emotional impact into account.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

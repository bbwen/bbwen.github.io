<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155581705-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-155581705-1');
  </script>


  <title>Bingbing Wen</title>

  <meta name="author" content="Yujie Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/img.png">
</head>

<body>


  <table style="width:120%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
<!--                <name>Bingbing Wen&#127752;</name>-->
                <name>Bingbing Wen</name>

              </p>
              <p>I am a PhD student at <a href="https://www.washington.edu/">University of Washington</a>. I'm fortunate to be advised by <a href="https://faculty.washington.edu/billhowe/">Prof. Bill Howe</a> and <a href="https://www.llwang.net/">Prof. Lucy Lu Wang</a>. I also work closely with <a href="https://homes.cs.washington.edu/~yuliats/">Prof. Yulia Tsvetkov</a>. I'm a member of <a href="https://www.raise.uw.edu/"> UW RAISE Center </a> and  <a href="https://aiclinic.uw.edu/"> The AI Clinic </a> </p>
              <p>My research focuses on building trustworthy foundation models. I work on three areas: data curation and synthesis for high-quality pretraining and posttraining, model efficient training such as mixture-of-LoRA experts and reinforcement learning, and human-aligned evaluation.</p>
              <p>During my PhD, I had the opportunity to conduct research internships at Apple, Microsoft Cloud AI, and OPPO Research, where I explored challenges in building large-scale AI systems. I also collaborate closely with the Allen Institute for AI. </p>
              <p>I actively mentor undergraduate and master students in developing and carrying out research projects--feel free to reach out if you're interested in my research or phd application. </p>
              <p style="text-align:center">
                <a href="mailto:bingbw@uw.edu">Email</a> &nbsp|&nbsp
                <a href="https://scholar.google.com/citations?user=Jt0E6FEAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
                <a href="https://twitter.com/bingbingwen1"> Twitter </a> &nbsp|&nbsp
<!--                <a href="./data/MartinKlissarov_resume.pdf"> CV </a>-->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/bingbing_sit.png"><img style="width:100%;max-width:100%;border-radius:15px" alt="profile photo" src="images/bingbing_sit.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- The News -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>   News </heading>
              <div class="container sidebar col-md-3">
            <div class="panel-group">
              <div class="panel panel-default">
                <div class="panel-heading">
                  <h4 class="panel-title"></h4>
                </div>
                <div class="panel-body" id="oScroll" >
                <div id="scroll">
                    <li><b>9/2025</b> Our paper about <a href="https://arxiv.org/abs/2506.18322"> MLLM spurious correlation </a> has been accepted by NeurIPS 2025!</li>

                  <li><b>7/2025</b> I presented our abstention survey in LLMs (oral presentation) and confidence calibration (poster) at ACL 2025!</li>

                  <li><b>7/2025</b> Our paper about <a href="https://openreview.net/pdf?id=EQIBB1BA6Y"> modular abstention</a> has been accepted by ICML 2025!</li>

                  <li><b>6/2025</b> I will start my summer internship at Apple as a research intern!</li>
                  <li><b>5/2025</b> Our paper about <a href="https://arxiv.org/pdf/2407.20177"> optimal data mixing in pretraining</a> has been accepted by COLM 2025!</li>

                    <li><b>5/2025</b> Our paper about <a href="https://arxiv.org/pdf/2506.00582"> confidence calibration</a> has been accepted by ACL 2025!</li>

                    <li><b>2/2025</b> Our paper about <a href="https://arxiv.org/pdf/2407.18418"> abstention survey in LLMs </a>  has been accepted by TACL 2025!</li>
<!-- 
                    <li><b>10/2024</b> Our paper about <a href="https://openreview.net/pdf?id=y9UdO5cmHs"> confidence estimation </a>  has been accepted by NeurIPS 2024!</li>

                    <li><b>9/2024</b> Our paper about <a href="https://arxiv.org/abs/2404.12452">evaluating models' abstention ability </a>  has been accepted by EMNLP2024!</li>


                <li><b>4/2024</b> One paper about <a href="https://dl.acm.org/doi/pdf/10.1145/3630106.3658966">laboratory-Scale AI</a>  has been accepted by FAccT2024!</li>

                <li><b>2/2024</b> One paper about <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_OmniMotionGPT_Animal_Motion_Generation_with_Limited_Data_CVPR_2024_paper.pdf">motion generation</a>  has been accepted by CVPR2024!</li> -->
<!--                <p></p>-->

<!--                  <li><b>1/2024</b> Submit one paper to ACL</li>-->
<!--                <p></p>-->

<!--                <li><b>1/2024</b> Submit one paper to FaCCT</li>-->
<!--                <p></p>-->


<!--                <li><b>07/2022</b> One paper about emoji visualization has been accepted at emoji workshop at NAACL 2022!</li>-->
<!--                <p></p>-->

<!--                <li><b>16/04/2022</b> Selected as an Highlighted Reviewer for ICLR 2022! Hopefully those reviews helped the authors.</li>-->
<!--                <p></p>-->

<!--                <li><b>15/10/2021</b> Selected as an Oustanding Reviewer (top 8%) for NeurIPS 2021! Amazing to be recognized for the time and thought put into the reviewing service.</li>-->
<!--                <p></p>-->


<!--                <li><b>28/09/2021</b> <i>"Flexible Option Learning"</i> has been accepted as a Spotlight to NeurIPS 2021! The paper and code will be out soon.</li>-->
<!--                <p></p>-->



<!--                <p></p>-->
<!--                <li><b>06/2022</b> Started a research internship about vision and language at Microsoft under the supervision of <a href="https://zyang-ur.github.io/">Zhengyuan Yang</a>.</li>-->
<!--                <p></p>-->


<!--                  <li><b>04/2022</b> Presented our <a href="https://dl.acm.org/doi/10.1145/3485447.3512269">paper</a> on evaluation for explainable recommendation at the Web Conference 2022!</li>-->
<!--                <p></p>-->

<!--                <p></p>                -->
<!--                <li><b>01/04/2021</b> Started a research internship at Microsoft Research Montreal under the supervision of Mehdi Fatemi and Romain Laroche.</li>-->
<!--                <p></p>-->


              </div>
            </div>
              </div>

            </td>
          </tr>
        </tbody></table>





        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" cellspacing="0" cellpadding="10">


          <tr>
            <td width="33%" valign="center" align="center"><img src="images/modular_abstention.png" alt="sym" width="100%" height="120" style="border-radius:1px">
            </td>
            <td width="67%" valign="top">
              <p><a id="modular abstention">
              <p><a href="https://openreview.net/pdf?id=EQIBB1BA6Y" id="modular abstention">
              <heading>MARVEL: Modular Abstention for Reliable and Versatile Expert LLMs</heading></a><br>
              <b>Bingbing Wen</b>,  Faeze Brahman, Zhan Su ,  Shangbin Feng, Yulia Tsvetkov, Lucy Lu Wang, Bill Howe<br>
              ICML Reliable Foundation Model Workshop  & NeurIPS Submission
              </p>
            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><img src="images/confidence_calibration.png" alt="sym" width="100%" height="120" style="border-radius:1px">
            </td>
            <td width="67%" valign="top">
              <p><a id="confidence calibration">
              <p><a href="https://arxiv.org/pdf/2506.00582" id="confidence calibration">
              <heading>Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs</heading></a><br>
              Chenjun Xu*,  <b>Bingbing Wen*</b>, Bin Han, Robert Wolfe, Lucy Lu Wang, Bill Howe<br>
                ACL2025 findings
              </p>

            <tr>
            <td width="33%" valign="center" align="center"><img src="images/abstention_survey.png" alt="sym" width="100%" height="120" style="border-radius:1px">
            </td>
            <td width="67%" valign="top">
              <p><a id="abstention_survey">
              <p><a href="https://arxiv.org/abs/2407.18418" id="abstention_survey">
              <heading>Know Your Limits: A Survey of Abstention in Large Language Models</heading></a><br>
                 <b>Bingbing Wen</b>, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, Lucy Lu Wang<br>
                TACL2025, ACL2025 Oral
              </p>

            </td>
          </tr>

            <tr>
            <td width="33%" valign="center" align="center"><img src="images/autoscale.png" alt="sym" width="100%" height="120" style="border-radius:1px">
            </td>
            <td width="67%" valign="top">
              <p><a id="autoscale">
              <p><a href="https://arxiv.org/pdf/2407.20177" id="autoscale">
              <heading>AutoScale-Automatic Prediction of Compute-optimal Data Composition for Training LLMs</heading></a><br>
                Feiyang Kang*, Yifan Sun*, <b>Bingbing Wen</b>, Si Chen, Dawn Song, Rafid Mahmood, Ruoxi Jia <br>
                COLM2025
              </p>

            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><img src="images/abstention_scienceqa.png" alt="sym" width="100%" height="120" style="border-radius:1px">
            </td>
            <td width="67%" valign="top">
              <p><a id="abstention_scienceqa">
              <p><a href="https://arxiv.org/abs/2404.12452" id="abstention_scienceqa">
              <heading>Characterizing LLM Abstention Behavior in Science QA with Context Perturbations</heading></a><br>
              <b>Bingbing Wen</b>,  Bill Howe, Lucy Lu Wang <br>
              EMNLP2024 Findings
              </p>

<!--            <div class="paper" id="Abstention">-->
<!--            &lt;!&ndash; <a href="https://sites.google.com/view/optionsofinterest">webpage</a> | &ndash;&gt;-->
<!--            <a href="https://openreview.net/pdf?id=L5vbEVIePyb">pdf</a>-->
<!--            | <a href="./data/flexible.bib">bibtex</a>-->
<!--            | <a href="https://github.com/mklissa/MOC">code</a>-->

<!--            </div>-->
            </td>
          </tr>








<!--          <tr>-->
<!--            <td width="33%" valign="center" align="center"><img src="images/legal.jpeg" alt="sym" width="80%" height="150" style="border-radius:1px">-->
<!--            </td>-->
<!--            <td width="67%" valign="top">-->
<!--              <p><a id="abstention_survey">-->
<!--              <heading>Benchmarking LLM's Information Extraction Ability on Legal Documents </heading></a><br>-->
<!--                Ongoing project-->
<!--              </p>-->

<!--            </td>-->
<!--          </tr>-->


<!--          <tr>-->
<!--            <td width="33%" valign="center" align="center"><img src="images/rag_tuning.png" alt="sym" width="80%" height="150" style="border-radius:1px">-->
<!--            </td>-->
<!--            <td width="67%" valign="top">-->
<!--              <p><a id="rag_tuning">-->
<!--              <heading> Retrieval-augmented Instruction Tuning for User-defined Tasks </heading></a><br>-->
<!--                Ongoing project-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2312.13503.pdf"><img src="images/InfoVisDial.png" alt="sym" width="100%" height="120" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/2312.13503.pdf" id="InfoVisDial">
              <heading>InfoVisDial: An Informative Visual Dialogue Dataset by Bridging Large Multimodal and Language Models</heading></a><br>
                <b>Bingbing Wen</b>,  Zhengyuan Yang, Jianfeng Wang, Zhe Gan, Bill Howe, Lijuan Wang<br>
                <br> Internship at Microsoft Azure AI <br>
              </p>



<!--            <div class="paper" id="optionsofinterest">-->
<!--            <a href="https://sites.google.com/view/optionsofinterest">webpage</a> |-->
<!--            <a href="https://128.84.21.199/pdf/2001.00271.pdf">pdf</a> |-->
<!--            <a href="./data/opint.bib">bibtex</a> |-->
<!--            <a href="https://github.com/kkhetarpal/ioc">code</a>-->

<!--            </div>-->
            </td>
          </tr>



          <tr>
            <td width="33%" valign="center" align="center"><a href="./data/ccq_aaai.pdf"><img src="images/ccq_aaai.png" alt="sym" width="100%" height="120"  style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="./data/ccq_aaai.pdf" id="ccq">
              <heading>CCQ: cross-class query network for partially labeled organ segmentation<br/> </heading></a><br>
               Xuyang Liu*, <b>Bingbing Wen*</b>,Sibei Yang<br>
                AAAI, 2023
              </p>


<!--            <div class="paper" id="neurips19">-->



<!--            <a href="https://tarl2019.github.io/assets/papers/klissarov2019variational.pdf">pdf</a> |-->
<!--                          <a href="./data/vse.bib">bibtex</a>-->


<!--            </div>-->
            </td>
          </tr>




          <tr>
            <td width="33%" valign="center" align="center"><a href="https://dl.acm.org/doi/pdf/10.1145/3485447.3512269"><img src="images/expscore.png" alt="sym" width="100%" height="120" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://dl.acm.org/doi/pdf/10.1145/3485447.3512269" id="ExpScore">
              <heading>ExpScore: Learning metrics for recommendation explanation<br/> </heading></a><br>
              <b>Bingbing Wen</b>,Yunhe Feng, Yongfeng Zhang, Chirag Shah<br>
              WWW, 2022
              </p>


<!--            <div class="paper" id="neurips19">-->
<!--            <a href="https://openreview.net/forum?id=BkgkoToZZ7">pdf</a>  |-->
<!--            <a href="./data/davf.bib">bibtex</a>-->

<!--            </div>-->
            </td>
          </tr>






<!--          <tr>-->
<!--            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/1709.04571.pdf"><img src="images/amidar_db2.png" alt="sym" width="80%" height="150" style="border-radius:15px"></a>-->
<!--            </td>-->
<!--            <td width="67%" valign="top">-->
<!--              <p><a href="https://arxiv.org/pdf/1709.04571.pdf" id="interest options">-->
<!--              <heading>When Waiting is not an Option:  Learning Options using the Deliberation Cost<br/> </heading></a><br>-->
<!--              Jean Harb, Pierre-Luc Bacon, <b>Bingbing Wen</b>,  Bill Howe<br>-->
<!--              Association for the Advancement of Artificial Intelligence (AAAI), 2018-->
<!--              </p>-->


<!--            <div class="paper" id="a2oc">-->

<!--            <a href="https://arxiv.org/pdf/1709.04571.pdf">pdf</a> |-->
<!--            <a href="./data/option_db.bib">bibtex</a> |-->
<!--            <a href="https://github.com/jeanharb/a2oc_delib">code</a>-->

<!--            </div>-->
<!--            </td>-->
<!--          </tr>-->




<!--          <tr>-->
<!--            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/1712.00004.pdf"><img src="images/ppoc.gif" alt="sym" width="80%" style="border-radius:15px"></a>-->
<!--            </td>-->
<!--            <td width="67%" valign="top">-->
<!--              <p><a href="https://arxiv.org/pdf/1712.00004.pdf" id="interest options">-->
<!--              <heading>Learning Options End-to-End for Continuous Action Tasks<br/> </heading></a><br>-->
<!--              <b>Bingbing Wen</b>, Pierre-Luc Bacon, Jean Harb,  Bill Howe<br>-->
<!--              Neural Information Processing Systems (NIPS) Hierarchichal Reinforcement Learning Workshop, 2017-->
<!--              </p>-->


<!--            <div class="paper" id="ppoc">-->
<!--            <a href="https://arxiv.org/pdf/1712.00004.pdf">pdf</a> |-->
<!--            <a href="./data/options_continuousactions.bib">bibtex</a> |-->
<!--            <a href="https://github.com/mklissa/PPOC">code</a>-->

<!--            </div>-->
<!--            </td>-->
<!--          </tr>-->


        </table>







<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Education</heading>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

<!--        <table width="100%" align="justify" border="0" cellspacing="15" cellpadding="10">-->


<!--          <tr>-->
<!--            <td width="15%" valign="center" align="center"><img src="images/mcgill.png" alt="mcgill" width="60" height="82"></td>-->
<!--            <td width="85%" valign="center">-->
<!--              <p>-->
<!--                <span><strong>McGill University</strong></span><span style="float:right">2020 - Present</span>-->
<!--                <br>-->
<!--                PhD in Computer Science-->
<!--                <br>-->
<!--                Supervisor: <a href="https://faculty.washington.edu/billhowe/"> Prof. Bill Howe</a>-->
<!--                <br>-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->


<!--          <tr>-->
<!--            <td width="15%" valign="center" align="center"><img src="images/mcgill.png" alt="mcgill" width="60" height="82"></td>-->
<!--            <td width="85%" valign="center">-->
<!--              <p>-->
<!--                <span><strong>McGill University</strong></span><span style="float:right">2018 - 2020</span>-->
<!--                <br>-->
<!--                MSc in Computer Science-->
<!--                <br>-->
<!--                Supervisor: <a href="https://faculty.washington.edu/billhowe/"> Prof. Bill Howe</a>-->
<!--                <br>-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->

<!--          <tr>-->
<!--            <td width="15%" valign="center" align="center"><img src="images/poly_logo.jpeg" alt="poly" width="80" height="80"></td>-->
<!--            <td width="85%" valign="center">-->
<!--              <p>-->
<!--                <span><strong>Polytechnique Montréal</strong></span><span style="float:right">2014 - 2018</span>-->
<!--                <br>-->
<!--                BEng in Electrical Engineering-->
<!--                <br>-->
<!--                Supervisor: <a href="https://www.calozc.org/"> Prof. Christophe Caloz</a>-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </table>-->



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Reviewing</heading>
    </td>
  </tr>
</tbody></table>

<table width="100%" align="center" border="0" cellpadding="0">
  <tr><td>
    <ul>
    <li> NeurIPS: 2023/2024 </li>
      <li> NeurIPS dataset and benchmark: 2023/2024 </li>
    <li> ICLR: 2023/2024 </li>
    <li> EMNLP: 2022/2023</li>
    <li> AAAI: 2024</li>
      <li> WACV: 2024/2025</li>
    </ul>
  </td></tr>



<!--<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--    <tr>-->
<!--    <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--      <heading>Organisation Comittee</heading>-->
<!--    </td>-->
<!--  </tr>-->
<!--</tbody></table>-->

<!--<table width="100%" align="center" border="0" cellpadding="0">-->
<!--  <tr><td>-->
<!--    <ul>-->
<!--    <li> CoLLAs: 2022 </li>-->
<!--    </ul>-->
<!--  </td></tr>-->

<!--<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--    <tr>-->
<!--    <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--      <heading>Selected Awards</heading>-->
<!--    </td>-->
<!--  </tr>-->
<!--</tbody></table>-->

<!--<table width="100%" align="center" border="0" cellpadding="0">-->
<!--  <tr><td>-->
<!--    <ul>-->
<!--     <li> Natural Sciences and Engineering Research Council of Canada (NSERC)  Alexander Graham Bell Canada Graduate Scholarship (2020-2023)</li>-->
<!--    <li> Fonds de Recherche du Québec - Nature et Technologie (FRQNT)  Masters Research Scholarship (2018-2020)</li>-->
<!--    <li> McGill Graduate Excellence Award (2018-2020)</li>-->
<!--    <li> Ordre des Ingénieurs Foundation Excellence Scholarship (2016)</li>-->
<!--    </ul>-->
<!--  </td></tr>-->
<!--</table>-->



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                A special thanks to Yujie Li </a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>









</body>

</html>
